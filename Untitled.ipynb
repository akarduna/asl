{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7493d20-6e51-4924-8446-8e24446d659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import color\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae18b31b-e73b-4045-b0fd-964fd4bbc440",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '~/ml/asl/asl_alphabet_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97ecea27-b531-40f3-97de-d4376b28e3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "color.rgb2gray(io.imread(data_dir+\"/B/B1.jpg\")).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3a36bcc1-9179-4d16-9eba-d4f802a582d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(124),\n",
    "                                transforms.ToTensor()\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b43bf773-b9fd-4af3-9fda-9f4ccd4c1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f045ce45-1951-41ce-aa70-68a6481fe0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = torchvision.datasets.ImageFolder(data_dir, transform=transform)\n",
    "trainSize = int(len(dataSet)*testPer)\n",
    "train, test = torch.utils.data.random_split(dataSet, [trainSize, len(dataSet)-trainSize], generator=torch.Generator().manual_seed(42))\n",
    "dataloader = torch.utils.data.DataLoader(train, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6dd21d9e-045b-4e2e-b21b-796c2f962ba1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'ToPILImage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30090/56511639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ToPILImage'"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(dataloader))\n",
    "images[0]\n",
    "plt.imshow(images[0].ToPILImage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b223d856-7e70-4693-9954-9c92ac16bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bathsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ea4fca31-48ad-4aa8-95ed-9e92bbb56a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=12544, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=29, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(12544, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "        self.fc4 = nn.Linear(64, 29)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7d099c36-9e90-450e-93e8-515690a41554",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nodes = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6019afe5-6d68-419f-b5a4-e73945f966b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # net = nn.Sequential(\n",
    "#     nn.Conv2d(3,no_nodes//8, 3),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(no_nodes//8,no_nodes//4,kernel_size=3),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(3),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(42632,64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64,32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32,29),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4f95bd1b-357f-4ab8-a95f-c68c4832c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5404c913-d2a4-437d-9d6c-515807e538a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            456\n",
      "├─MaxPool2d: 1-2                         --\n",
      "├─Conv2d: 1-3                            2,416\n",
      "├─Linear: 1-4                            1,505,400\n",
      "├─Linear: 1-5                            10,164\n",
      "├─Linear: 1-6                            5,440\n",
      "├─Linear: 1-7                            1,885\n",
      "=================================================================\n",
      "Total params: 1,525,761\n",
      "Trainable params: 1,525,761\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Conv2d: 1-1                            456\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            2,416\n",
       "├─Linear: 1-4                            1,505,400\n",
       "├─Linear: 1-5                            10,164\n",
       "├─Linear: 1-6                            5,440\n",
       "├─Linear: 1-7                            1,885\n",
       "=================================================================\n",
       "Total params: 1,525,761\n",
       "Trainable params: 1,525,761\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d6cec1ba-5d82-4f39-b170-0a47ccc0e3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = images[0:4]\n",
    "inp.shape\n",
    "out = net(inp)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fbfad406-e753-4197-b1c7-a0342d628c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5e81fcbf-7357-4eac-b3b0-2233ecb4d8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 1.537\n",
      "[2,    50] loss: 1.500\n",
      "[3,    50] loss: 1.430\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        # labels = F.one_hot(labels)\n",
    "        # labels = torch.tensor(labels, dtype=torch.float,device=\"cpu\")\n",
    "        # print(labels)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i%50==49:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss/50))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "64ad872c-edb7-4895-af9d-a66543d3d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6405\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "count = 0\n",
    "correct = 0\n",
    "for batch, (X, y) in enumerate(test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = net(X.unsqueeze(0))\n",
    "        predicted, actual = pred[0].argmax(0), y\n",
    "        count += 1\n",
    "        if predicted == actual:\n",
    "            correct+=1\n",
    "        if count == 2000:\n",
    "            break\n",
    "print(correct/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b55a937f-dfb5-46d1-883c-1d450927233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(net.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c5917212-d2b1-438c-8f68-d4882447f009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4619678c-82da-47e9-a673-1eb4550b4d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6405\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "count = 0\n",
    "correct = 0\n",
    "for batch, (X, y) in enumerate(test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X.unsqueeze(0))\n",
    "        predicted, actual = pred[0].argmax(0), y\n",
    "        count += 1\n",
    "        if predicted == actual:\n",
    "            correct+=1\n",
    "        if count == 2000:\n",
    "            break\n",
    "print(correct/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d712e-9a23-4e9a-a397-d8a418f22566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
